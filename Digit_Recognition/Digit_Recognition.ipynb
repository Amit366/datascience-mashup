{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22a0f150fc8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "f, axarr = plt.subplots(4,3)\n",
    "axarr[0,0].imshow(digits.images[0])\n",
    "axarr[0,1].imshow(digits.images[1])\n",
    "axarr[0,2].imshow(digits.images[2])\n",
    "axarr[1,0].imshow(digits.images[3])\n",
    "axarr[1,1].imshow(digits.images[4])\n",
    "axarr[1,2].imshow(digits.images[5])\n",
    "axarr[2,0].imshow(digits.images[6])\n",
    "axarr[2,1].imshow(digits.images[7])\n",
    "axarr[2,2].imshow(digits.images[8])\n",
    "axarr[3,0].imshow(digits.images[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    \"\"\"Class for training and using a model for logistic regression\"\"\"\n",
    "    \n",
    "    def set_values(self, initial_params, alpha=0.01, iter_max=5000, class_interest=0):\n",
    "        \"\"\"Set the values for initial params, step size, maximum iteration, and class of interest\"\"\"\n",
    "        \n",
    "        self.params = initial_params\n",
    "        self.alpha = alpha\n",
    "        self.iter_max = iter_max\n",
    "        self.class_interest = class_interest\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(a):\n",
    "        \"\"\"Sigmoide function\"\"\"\n",
    "        \n",
    "        return 1.0 / (1.0 + np.exp(-a))\n",
    "    \n",
    "    def predict(self, bar_a, params):\n",
    "        \"\"\"predict the probability of a class\"\"\"  \n",
    "                \n",
    "        return self._sigmoid(np.dot(params, bar_a))\n",
    "    \n",
    "    def _compute_cost(self, input_var, output_var, params):\n",
    "        \"\"\"Compute the log likelihood cost\"\"\"\n",
    "        \n",
    "        cost = 0\n",
    "        for x, y in zip(input_var, output_var):\n",
    "            bar_a = np.array(np.insert(x, 0, 1))\n",
    "            y_hat = self.predict(bar_a, params)\n",
    "            \n",
    "            y_binary = 1.0 if y == self.class_interest else 0.0\n",
    "            cost += y_binary * np.log(y_hat) + (1.0 - y_binary) * np.log(1 - y_hat)\n",
    "            \n",
    "        return cost\n",
    "    \n",
    "    def train(self, input_var, label, iter_print = 5000):\n",
    "        \"\"\"Train the model \"\"\"\n",
    "        \n",
    "        iteration = 1\n",
    "        while iteration < self.iter_max:\n",
    "            if iteration % iter_print == 0:\n",
    "                print(f'iteration: {iteration}')\n",
    "                print(f'cost: {self._compute_cost(input_var, label, self.params)}')\n",
    "                print('--------------------------------------------')\n",
    "            \n",
    "            for i, xy in enumerate(zip(input_var, label)):\n",
    "                bar_a = np.array(np.insert(xy[0], 0, 1))\n",
    "                y_hat = self.predict(bar_a, self.params)\n",
    "                \n",
    "                y_binary = 1.0 if xy[1] == self.class_interest else 0.0\n",
    "                gradient = (y_binary - y_hat) * bar_a\n",
    "                self.params += self.alpha * gradient\n",
    "            \n",
    "            iteration +=1\n",
    "        \n",
    "        return self.params\n",
    "\n",
    "    def test(self, input_test, test_label):\n",
    "        \"\"\"Test the accuracy of the model \"\"\"\n",
    "        \n",
    "        self.total_classifications = 0\n",
    "        self.correct_classifications = 0\n",
    "        \n",
    "        for x,y in zip(input_test, test_label):\n",
    "            self.total_classifications += 1\n",
    "            bar_a = np.array(np.insert(x, 0, 1))\n",
    "            y_hat = self.predict(bar_a, self.params)\n",
    "            y_binary = 1.0 if y == self.class_interest else 0.0\n",
    "            \n",
    "            if y_hat >= 0.5 and  y_binary == 1:\n",
    "                # correct classification of class_of_interest\n",
    "                self.correct_classifications += 1\n",
    "              \n",
    "            if y_hat < 0.5 and  y_binary != 1:\n",
    "                # correct classification of an other class\n",
    "                self.correct_classifications += 1\n",
    "                \n",
    "        self.accuracy = self.correct_classifications / self.total_classifications\n",
    "            \n",
    "        return self.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to training and test sets\n",
    "train_digits, test_digits, digits_label_train, digits_label_test =\\\n",
    "train_test_split(digits.data, digits.target, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1000\n",
      "cost: -1.8617723833598285\n",
      "--------------------------------------------\n",
      "iteration: 2000\n",
      "cost: -1.04813941096907\n",
      "--------------------------------------------\n",
      "iteration: 3000\n",
      "cost: -0.7367924255634913\n",
      "--------------------------------------------\n",
      "iteration: 4000\n",
      "cost: -0.5702400317991684\n",
      "--------------------------------------------\n",
      "iteration: 5000\n",
      "cost: -0.46601609233456326\n",
      "--------------------------------------------\n",
      "iteration: 6000\n",
      "cost: -0.39446312793281285\n",
      "--------------------------------------------\n",
      "iteration: 7000\n",
      "cost: -0.34221929379689436\n",
      "--------------------------------------------\n",
      "iteration: 8000\n",
      "cost: -0.3023567591354298\n",
      "--------------------------------------------\n",
      "iteration: 9000\n",
      "cost: -0.27091771337070814\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# train a classifier for the ZERO digit\n",
    "alpha = 1e-2\n",
    "params_0 = np.zeros(len(digits.data[0]) + 1)\n",
    "\n",
    "iter_max = 10000\n",
    "digits_regression_model_0 = LogisticRegression()\n",
    "digits_regression_model_0.set_values(params_0, alpha, iter_max, 0)\n",
    "\n",
    "params =\\\n",
    "digits_regression_model_0.train(train_digits / 16.0, digits_label_train, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediciting a ONE digit in test set: 1.0\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "accuracy = digits_regression_model_0.test(test_digits / 16.0, digits_label_test)\n",
    "print(f'Accuracy of prediciting a ONE digit in test set: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1000\n",
      "cost: -29.880010627991478\n",
      "--------------------------------------------\n",
      "iteration: 2000\n",
      "cost: -23.89083533706708\n",
      "--------------------------------------------\n",
      "iteration: 3000\n",
      "cost: -20.98449971808456\n",
      "--------------------------------------------\n",
      "iteration: 4000\n",
      "cost: -19.13182920303362\n",
      "--------------------------------------------\n",
      "iteration: 5000\n",
      "cost: -17.794194844846004\n",
      "--------------------------------------------\n",
      "iteration: 6000\n",
      "cost: -16.75601529792599\n",
      "--------------------------------------------\n",
      "iteration: 7000\n",
      "cost: -15.911384332272544\n",
      "--------------------------------------------\n",
      "iteration: 8000\n",
      "cost: -15.201148715363093\n",
      "--------------------------------------------\n",
      "iteration: 9000\n",
      "cost: -14.589201614485031\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# train a classifier for the ONE digit\n",
    "alpha = 1e-2\n",
    "params_0 = np.zeros(len(digits.data[0]) + 1)\n",
    "\n",
    "iter_max = 10000\n",
    "digits_regression_model_1 = LogisticRegression()\n",
    "digits_regression_model_1.set_values(params_0, alpha, iter_max, 1)\n",
    "\n",
    "params =\\\n",
    "digits_regression_model_1.train(train_digits / 16.0, digits_label_train, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediciting a TWO digit in test set: 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "accuracy = digits_regression_model_1.test(test_digits / 16.0, digits_label_test)\n",
    "print(f'Accuracy of prediciting a ONE digit in test set: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1000\n",
      "cost: -1.8617723833598285\n",
      "--------------------------------------------\n",
      "iteration: 2000\n",
      "cost: -1.04813941096907\n",
      "--------------------------------------------\n",
      "iteration: 3000\n",
      "cost: -0.7367924255634913\n",
      "--------------------------------------------\n",
      "iteration: 4000\n",
      "cost: -0.5702400317991684\n",
      "--------------------------------------------\n",
      "iteration: 5000\n",
      "cost: -0.46601609233456326\n",
      "--------------------------------------------\n",
      "iteration: 6000\n",
      "cost: -0.39446312793281285\n",
      "--------------------------------------------\n",
      "iteration: 7000\n",
      "cost: -0.34221929379689436\n",
      "--------------------------------------------\n",
      "iteration: 8000\n",
      "cost: -0.3023567591354298\n",
      "--------------------------------------------\n",
      "iteration: 9000\n",
      "cost: -0.27091771337070814\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# train a classifier for the TWO digit\n",
    "alpha = 1e-2\n",
    "params_0 = np.zeros(len(digits.data[0]) + 1)\n",
    "\n",
    "iter_max = 10000\n",
    "digits_regression_model_2 = LogisticRegression()\n",
    "digits_regression_model_2.set_values(params_0, alpha, iter_max, 0)\n",
    "\n",
    "params =\\\n",
    "digits_regression_model_2.train(train_digits / 16.0, digits_label_train, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediciting a TWO digit in test set: 1.0\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "accuracy = digits_regression_model_2.test(test_digits / 16.0, digits_label_test)\n",
    "print(f'Accuracy of prediciting a TWO digit in test set: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1000\n",
      "cost: -4.618298287392253\n",
      "--------------------------------------------\n",
      "iteration: 2000\n",
      "cost: -2.6344706618056746\n",
      "--------------------------------------------\n",
      "iteration: 3000\n",
      "cost: -1.8601914108714526\n",
      "--------------------------------------------\n",
      "iteration: 4000\n",
      "cost: -1.4429886205888383\n",
      "--------------------------------------------\n",
      "iteration: 5000\n",
      "cost: -1.1809426351496592\n",
      "--------------------------------------------\n",
      "iteration: 6000\n",
      "cost: -1.0006285680316993\n",
      "--------------------------------------------\n",
      "iteration: 7000\n",
      "cost: -0.868766416732642\n",
      "--------------------------------------------\n",
      "iteration: 8000\n",
      "cost: -0.7680366369924487\n",
      "--------------------------------------------\n",
      "iteration: 9000\n",
      "cost: -0.6885195187394286\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# train a classifier for the Seven digit\n",
    "alpha = 1e-2\n",
    "params_0 = np.zeros(len(digits.data[0]) + 1)\n",
    "\n",
    "iter_max = 10000\n",
    "digits_regression_model_7 = LogisticRegression()\n",
    "digits_regression_model_7.set_values(params_0, alpha, iter_max, 7)\n",
    "\n",
    "params =\\\n",
    "digits_regression_model_7.train(train_digits / 16.0, digits_label_train, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediciting a Seven digit in test set: 0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "accuracy = digits_regression_model_7.test(test_digits / 16.0, digits_label_test)\n",
    "print(f'Accuracy of prediciting a Seven digit in test set: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1000\n",
      "cost: -32.746521355146996\n",
      "--------------------------------------------\n",
      "iteration: 2000\n",
      "cost: -28.064528588325384\n",
      "--------------------------------------------\n",
      "iteration: 3000\n",
      "cost: -25.658505602279135\n",
      "--------------------------------------------\n",
      "iteration: 4000\n",
      "cost: -24.085544443356067\n",
      "--------------------------------------------\n",
      "iteration: 5000\n",
      "cost: -22.93840626335799\n",
      "--------------------------------------------\n",
      "iteration: 6000\n",
      "cost: -22.044948510192242\n",
      "--------------------------------------------\n",
      "iteration: 7000\n",
      "cost: -21.317101611972184\n",
      "--------------------------------------------\n",
      "iteration: 8000\n",
      "cost: -20.70444111789916\n",
      "--------------------------------------------\n",
      "iteration: 9000\n",
      "cost: -20.175789729721423\n",
      "--------------------------------------------\n",
      "iteration: 10000\n",
      "cost: -19.71072662335057\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# train a classifier for the Nine digit\n",
    "alpha = 1e-2\n",
    "params_0 = np.zeros(len(digits.data[0]) + 1)\n",
    "\n",
    "iter_max = 11000\n",
    "digits_regression_model_9 = LogisticRegression()\n",
    "digits_regression_model_9.set_values(params_0, alpha, iter_max, 9)\n",
    "\n",
    "params =\\\n",
    "digits_regression_model_9.train(train_digits / 16.0, digits_label_train, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediciting a NINE digit in test set: 0.9694444444444444\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "accuracy = digits_regression_model_9.test(test_digits / 16.0, digits_label_test)\n",
    "print(f'Accuracy of prediciting a NINE digit in test set: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
